{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a29c272",
   "metadata": {},
   "source": [
    "# **XAI4Spectra**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f398e",
   "metadata": {},
   "source": [
    "# **Loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7cf76ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kennard_stone as ks\n",
    "\n",
    "# loading a soil spectral dataset based on X-ray fluorescence (XRF)\n",
    "\n",
    "data_complete = pd.read_csv('https://raw.githubusercontent.com/joseviniciusr/XAI4Spectra/refs/heads/main/Toledo22.csv', sep=';')\n",
    "data = data_complete.loc[:, '1':'15']\n",
    "data.insert(0, 'exCa', data_complete['exCa'])  # inserting the target variable (e.g., exCa (exchangeable calcium))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f534cc2c",
   "metadata": {},
   "source": [
    "## **PLS- (R or DA) modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44153202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explained_variance_from_scores(X, T, P, Q=None, Y=None):\n",
    "    \"\"\"\n",
    "    Calculate percent variance explained (based on PCTVAR Matlab function) for X and Y\n",
    "    by using the scores T and loadings P (and optionally Q for Y).\n",
    "    Parameters\n",
    "    ----------\n",
    "    - **X** : array-like, shape (n_samples, n_features)\n",
    "        X matrix used in PLS.\n",
    "    - **T** : array-like, shape (n_samples, n_components)\n",
    "        Scores matrix from PLS.\n",
    "    - **P** : array-like, shape (n_features, n_components)\n",
    "        Loadings matrix for X from PLS.\n",
    "    - **Q** : array-like, shape (n_targets, n_components), optional\n",
    "        Loadings matrix for Y from PLS. Required if Yc is provided.\n",
    "    - **Y** : array-like, shape (n_samples, n_targets), optional\n",
    "       Y matrix used in PLS.\n",
    "    Returns\n",
    "    -------\n",
    "    - result : dict with keys:\n",
    "        - **'varX_cumulative'** : ndarray shape (n_components,)\n",
    "            Percent cumulative variance of X explained by 1..j components.\n",
    "        - **'varX_per_component'** : ndarray shape (n_components,)\n",
    "            Percent variance of X explained per component.\n",
    "        - **'varY_cumulative'** : ndarray shape (n_components,), or None\n",
    "            Percent cumulative variance of Y explained by 1..j components (if Yc and Q provided).\n",
    "        - **'varY_per_component'** : ndarray shape (n_components,), or None\n",
    "            Percent variance of Y explained per component (if Yc and Q provided).\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    X = np.asarray(X, dtype=float) # X preprocessed data\n",
    "    T = np.asarray(T, dtype=float) # scores\n",
    "    P = np.asarray(P, dtype=float) # loadings for X\n",
    "\n",
    "    n_comp = T.shape[1]\n",
    "    TSS_X = np.sum(X ** 2) # total sum of squares of X\n",
    "    if TSS_X == 0: # avoid division by zero\n",
    "        raise ValueError(\"TSS_X == 0 (X does not have variability).\")\n",
    "\n",
    "    pctvarX_cum = np.zeros(n_comp, dtype=float) # cumulative percent variance for X\n",
    "\n",
    "    for j in range(1, n_comp + 1): # loop over components\n",
    "        Xhat_j = T[:, :j] @ P[:, :j].T # reconstructed X using j components\n",
    "        SS_Xhat_j = np.sum(Xhat_j ** 2) # sum of squares of reconstructed X\n",
    "        pctvarX_cum[j-1] = 100.0 * SS_Xhat_j / TSS_X # percent variance explained cumulativa\n",
    "    \n",
    "    # incremental (per component)\n",
    "    pctvarX_per = np.empty_like(pctvarX_cum) # incremental percent variance for X\n",
    "    pctvarX_per[0] = pctvarX_cum[0] # first component\n",
    "    pctvarX_per[1:] = pctvarX_cum[1:] - pctvarX_cum[:-1] # rest\n",
    "\n",
    "    # Y (if provided)\n",
    "    pctvarY_cum = None # cumulative percent variance for Y\n",
    "    pctvarY_per = None # incremental percent variance for Y\n",
    "    if Q is not None and Y is not None: # if Y loadings and Y centered provided\n",
    "        Q = np.asarray(Q, dtype=float) # loadings for Y\n",
    "        Y = np.asarray(Y, dtype=float) # centered (and possibly scaled) Y\n",
    "        TSS_Y = np.sum(Y ** 2) # total sum of squares of Y\n",
    "        if TSS_Y == 0: # avoid division by zero\n",
    "            pctvarY_cum = np.zeros(n_comp, dtype=float) # all zeros if Y has no variance\n",
    "            pctvarY_per = np.zeros(n_comp, dtype=float) # all zeros\n",
    "        else:\n",
    "            pctvarY_cum = np.zeros(n_comp, dtype=float) # cumulative percent variance for Y\n",
    "            for j in range(1, n_comp + 1): # loop over components\n",
    "                Yhat_j = T[:, :j] @ Q[:, :j].T # reconstructed Y using j components\n",
    "                SS_Yhat_j = np.sum(Yhat_j ** 2) # sum of squares of reconstructed Y\n",
    "                pctvarY_cum[j-1] = 100.0 * SS_Yhat_j / TSS_Y # percent variance explained cumulativa\n",
    "            pctvarY_per = np.empty_like(pctvarY_cum) # incremental percent variance for Y\n",
    "            pctvarY_per[0] = pctvarY_cum[0] # first component\n",
    "            pctvarY_per[1:] = pctvarY_cum[1:] - pctvarY_cum[:-1] # rest\n",
    "\n",
    "        return {\n",
    "            'varX_cumulative': pctvarX_cum[-1],\n",
    "            'varX_per_component': pctvarX_per[-1],\n",
    "            'varY_cumulative': pctvarY_cum[-1],\n",
    "            'varY_per_component': pctvarY_per[-1]\n",
    "            }         \n",
    "\n",
    "\n",
    "def pls_optimized(Xcal, ycal, LVmax, Xpred=None, ypred=None, aim='regression', cv=10):\n",
    "    \"\"\"\n",
    "    ## PLS optimized\n",
    "    Function to fit a PLS regression or PLS-DA model with optimization of latent variables (LVs)\n",
    "    using cross-validation. It calculates various performance metrics for calibration, cross-validation,\n",
    "    and prediction (if provided) datasets\n",
    "    **Parameters**:\n",
    "    - **Xcal** : pd.DataFrame\n",
    "        Calibration dataset features.\n",
    "    - **ycal** : pd.Series or np.ndarray\n",
    "        Calibration dataset target variable (regression) or binary class labels (classification).\n",
    "    - **LVmax** : int\n",
    "        Maximum number of latent variables to consider.\n",
    "    - **Xpred** : pd.DataFrame, optional\n",
    "        Prediction dataset features. Default is None.\n",
    "    - **ypred** : pd.Series or np.ndarray, optional\n",
    "        Prediction dataset target variable (regression) or binary class labels (classification). Default is None.\n",
    "    - **aim** : str, optional\n",
    "        Type of analysis: 'regression' for PLS regression or 'classification' for PLS-DA. Default is 'regression'.\n",
    "    - **cv** : int, optional\n",
    "        Number of cross-validation folds. Default is 10\n",
    "        \n",
    "    **Returns**:\n",
    "    - **df_results** : pd.DataFrame\n",
    "        DataFrame containing performance metrics for each number of latent variables.\n",
    "    - **calres** : pd.DataFrame\n",
    "        DataFrame containing predicted values for the calibration dataset.\n",
    "    - **predres** : pd.DataFrame\n",
    "        DataFrame containing predicted values for the prediction dataset (if provided).\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    if aim == 'regression': # regression (PLSR)\n",
    "        from sklearn.cross_decomposition import PLSRegression\n",
    "        from sklearn.model_selection import cross_val_predict\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from scipy.stats import iqr\n",
    "\n",
    "        results = [] # list to store results for each LV\n",
    "        calres = pd.DataFrame(index=range(len(ycal))) # calibration results\n",
    "        predres = pd.DataFrame(index=range(len(ypred))) if (Xpred is not None and ypred is not None) else None # prediction results\n",
    "\n",
    "        for n_comp in range(1, LVmax + 1): # loop over number of components\n",
    "            plsr = PLSRegression(n_components=n_comp, scale=False)\n",
    "            plsr.fit(Xcal, ycal)\n",
    "            y_cal = plsr.predict(Xcal).flatten()\n",
    "            calres[f'LV_{n_comp}'] = y_cal\n",
    "\n",
    "            y_cv = cross_val_predict(plsr, Xcal, ycal, cv=cv) # cross-validated predictions\n",
    "            y_cv = np.array(y_cv).flatten()\n",
    "\n",
    "            r2_cal = r2_score(ycal, y_cal)\n",
    "            rmse_cal = np.sqrt(mean_squared_error(ycal, y_cal))\n",
    "            r2_cv = r2_score(ycal, y_cv)\n",
    "            rmsecv = np.sqrt(mean_squared_error(ycal, y_cv))\n",
    "            rpd_cv = ycal.std() / rmsecv if rmsecv != 0 else np.nan\n",
    "            rpiq_cv = iqr(ycal, rng=(25, 75)) / rmsecv if rmsecv != 0 else np.nan\n",
    "            bias_cv = np.sum(ycal - y_cv) / ycal.shape[0]\n",
    "            SDV_cv = (ycal - y_cv) - bias_cv\n",
    "            SDV_cv = np.sqrt(np.sum(SDV_cv * SDV_cv) / (ycal.shape[0] - 1)) if ycal.shape[0] > 1 else np.nan\n",
    "            tbias_cv = abs(bias_cv) * (np.sqrt(ycal.shape[0]) / SDV_cv) if SDV_cv not in (0, np.nan) else np.nan\n",
    "            \n",
    "            # explained variance\n",
    "            exp_var = explained_variance_from_scores(Xcal, plsr.x_scores_, plsr.x_loadings_,\n",
    "                                               Q=plsr.y_loadings_, Y=ycal) # explained variance\n",
    "            \n",
    "            if Xpred is not None and ypred is not None: # prediction set\n",
    "                y_pred = plsr.predict(Xpred).flatten()\n",
    "                predres[f'LV_{n_comp}'] = y_pred\n",
    "\n",
    "                r2_pred = r2_score(ypred, y_pred)\n",
    "                rmsep = np.sqrt(mean_squared_error(ypred, y_pred))\n",
    "                rpd_pred = ypred.std() / rmsep if rmsep != 0 else np.nan\n",
    "                rpiq_pred = iqr(ypred, rng=(25, 75)) / rmsep if rmsep != 0 else np.nan\n",
    "                bias_pred = np.sum(ypred - y_pred) / ypred.shape[0]\n",
    "                SDV_pred = (ypred - y_pred) - bias_pred\n",
    "                SDV_pred = np.sqrt(np.sum(SDV_pred * SDV_pred) / (ypred.shape[0] - 1)) if ypred.shape[0] > 1 else np.nan\n",
    "                tbias_pred = abs(bias_pred) * (np.sqrt(ypred.shape[0]) / SDV_pred) if SDV_pred not in (0, np.nan) else np.nan\n",
    "            else:\n",
    "                r2_pred = rmsep = rpd_pred = rpiq_pred = bias_pred = tbias_pred = None\n",
    "\n",
    "            results.append({\n",
    "                'LVs': n_comp,\n",
    "                'R2 Cal': r2_cal,\n",
    "                'RMSEC': rmse_cal,\n",
    "                'R2 CV': r2_cv,\n",
    "                'RMSECV': rmsecv,\n",
    "                'RPD CV': rpd_cv,\n",
    "                'RPIQ CV': rpiq_cv,\n",
    "                'Bias_CV': bias_cv,\n",
    "                'tbias_CV': tbias_cv,\n",
    "                'R2 Pred': r2_pred,\n",
    "                'RMSEP': rmsep,\n",
    "                'RPD Pred': rpd_pred,\n",
    "                'RPIQ Pred': rpiq_pred,\n",
    "                'Bias_Pred': bias_pred,\n",
    "                'tbias_Pred': tbias_pred,\n",
    "                'X Cum Exp Var' : exp_var['varX_cumulative'],\n",
    "                'Y Cum Exp Var' : exp_var['varY_cumulative'],\n",
    "                'X Ind Exp Var' : exp_var['varX_per_component'],\n",
    "                'Y Ind Exp Var' : exp_var['varY_per_component']\n",
    "            })\n",
    "\n",
    "        model = plsr  # last model fitted\n",
    "        df_results = pd.DataFrame(results)\n",
    "        calres.insert(0, 'Ref', np.array(ycal))\n",
    "        if predres is not None:\n",
    "            predres.insert(0, 'Ref', np.array(ypred))\n",
    "\n",
    "    elif aim == 'classification': # classification (PLS-DA)\n",
    "        from sklearn.cross_decomposition import PLSRegression\n",
    "        from sklearn.model_selection import cross_val_predict\n",
    "        from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "        results = []\n",
    "        calres = pd.DataFrame(index=range(len(ycal))) # calibration results\n",
    "        predres = pd.DataFrame(index=range(len(ypred))) if (Xpred is not None and ypred is not None) else None # prediction results\n",
    "\n",
    "        # ensure binary classes\n",
    "        ycal_series = pd.Series(ycal).reset_index(drop=True) # ensure it's a Series\n",
    "        unique_labels = ycal_series.unique() # unique class labels\n",
    "        if len(unique_labels) != 2: # check for binary classification\n",
    "            raise ValueError(f\"PLS-DA (this function) expects 2 classes (binary). Found: {unique_labels}\")\n",
    "\n",
    "        label_to_num = {lab: idx for idx, lab in enumerate(unique_labels)} # mapping labels to 0 and 1\n",
    "        num_to_label = {idx: lab for lab, idx in label_to_num.items()} # reverse mapping for predictions\n",
    "       \n",
    "        # prepare ycal numeric\n",
    "        ycal_numeric = np.array([label_to_num[i] for i in ycal]) \n",
    "\n",
    "        # prepare ypred numeric if provided\n",
    "        ypred_numeric = None\n",
    "        if ypred is not None:\n",
    "            ypred_numeric = np.array([label_to_num[i] for i in ypred])\n",
    "\n",
    "        for n_comp in range(1, LVmax + 1): # loop over number of components\n",
    "            plsda = PLSRegression(n_components=n_comp, scale=False)\n",
    "            plsda.fit(Xcal, ycal_numeric)\n",
    "\n",
    "            # calibration continuous predictions -> binarize\n",
    "            y_cal_cont = plsda.predict(Xcal).flatten()\n",
    "            y_cal_bin = (y_cal_cont >= 0.5).astype(int)\n",
    "            y_cal_class = np.array([num_to_label[i] for i in y_cal_bin])\n",
    "            calres[f'LV_{n_comp}'] = y_cal_class\n",
    "\n",
    "            # cross-validated continuous predictions -> binarize\n",
    "            y_cv_cont = cross_val_predict(plsda, Xcal, ycal_numeric, cv=cv)\n",
    "            y_cv_cont = np.array(y_cv_cont).flatten()\n",
    "            y_cv_bin = (y_cv_cont >= 0.5).astype(int)\n",
    "\n",
    "            # metrics\n",
    "            acc_cal = accuracy_score(ycal_numeric, y_cal_bin)\n",
    "            cm_cal = confusion_matrix(ycal_numeric, y_cal_bin)\n",
    "            # safe unpack for binary confusion matrix\n",
    "            if cm_cal.size == 4:\n",
    "                tn, fp, fn, tp = cm_cal.ravel()\n",
    "            else:\n",
    "                tn = fp = fn = tp = np.nan\n",
    "            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
    "            specificity = tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
    "\n",
    "            acc_cv = accuracy_score(ycal_numeric, y_cv_bin)\n",
    "            cm_cv = confusion_matrix(ycal_numeric, y_cv_bin)\n",
    "            if cm_cv.size == 4:\n",
    "                tn_cv, fp_cv, fn_cv, tp_cv = cm_cv.ravel()\n",
    "            else:\n",
    "                tn_cv = fp_cv = fn_cv = tp_cv = np.nan\n",
    "            sensitivity_cv = tp_cv / (tp_cv + fn_cv) if (tp_cv + fn_cv) > 0 else np.nan\n",
    "            specificity_cv = tn_cv / (tn_cv + fp_cv) if (tn_cv + fp_cv) > 0 else np.nan\n",
    "\n",
    "            # explained variance\n",
    "            exp_var = explained_variance_from_scores(Xcal, plsda.x_scores_, plsda.x_loadings_,\n",
    "                                               Q=plsda.y_loadings_, Y=ycal_numeric.reshape(-1, 1)) # explained variance\n",
    "\n",
    "            # prediction set (if provided)\n",
    "            if Xpred is not None and ypred is not None:\n",
    "                y_pred_cont = plsda.predict(Xpred).flatten()\n",
    "                y_pred_bin = (y_pred_cont >= 0.5).astype(int)\n",
    "                y_pred_class = np.array([num_to_label[i] for i in y_pred_bin])\n",
    "                predres[f'LV_{n_comp}'] = y_pred_class\n",
    "\n",
    "                acc_pred = accuracy_score(ypred_numeric, y_pred_bin)\n",
    "                cm_pred = confusion_matrix(ypred_numeric, y_pred_bin)\n",
    "                if cm_pred.size == 4:\n",
    "                    tn_p, fp_p, fn_p, tp_p = cm_pred.ravel()\n",
    "                else:\n",
    "                    tn_p = fp_p = fn_p = tp_p = np.nan\n",
    "                sensitivity_p = tp_p / (tp_p + fn_p) if (tp_p + fn_p) > 0 else np.nan\n",
    "                specificity_p = tn_p / (tn_p + fp_p) if (tn_p + fp_p) > 0 else np.nan\n",
    "            else:\n",
    "                acc_pred = sensitivity_p = specificity_p = cm_pred = tn_p = fp_p = fn_p = tp_p = None\n",
    "\n",
    "            results.append({\n",
    "                'LVs': n_comp,\n",
    "                'Accuracy Cal': acc_cal,\n",
    "                'Sensitivity Cal': sensitivity,\n",
    "                'Specificity Cal': specificity,\n",
    "                'CM Cal': cm_cal,\n",
    "                'Accuracy CV': acc_cv,\n",
    "                'Sensitivity CV': sensitivity_cv,\n",
    "                'Specificity CV': specificity_cv,\n",
    "                'CM CV': cm_cv,\n",
    "                'Accuracy Pred': acc_pred,\n",
    "                'Sensitivity Pred': sensitivity_p,\n",
    "                'Specificity Pred': specificity_p,\n",
    "                'CM Pred': cm_pred,\n",
    "                'X Cum Exp Var' : exp_var['varX_cumulative'],\n",
    "                'Y Cum Exp Var' : exp_var['varY_cumulative'],\n",
    "                'X Ind Exp Var' : exp_var['varX_per_component'],\n",
    "                'Y Ind Exp Var' : exp_var['varY_per_component']\n",
    "            })\n",
    "\n",
    "        model = plsda  # last model fitted\n",
    "        df_results = pd.DataFrame(results)\n",
    "        calres.insert(0, 'Ref', np.array(ycal))\n",
    "        if predres is not None:\n",
    "            predres.insert(0, 'Ref', np.array(ypred))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Parameter `aim` must be 'regression' or 'classification'.\")\n",
    "\n",
    "    return df_results, calres, predres, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520ea092",
   "metadata": {},
   "source": [
    "# **Classification case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f976004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column 'Class' based on the condition of 'BSP' values\n",
    "data_complete['Class'] = np.where(data_complete['BSP'] > 50.00, 'eut', 'dist') # eutrophic (eut) if BSP > 50.00 (higher fertility), otherwise dystrophic (dist)\n",
    "data_eut = data_complete[data_complete['Class'] == 'eut'].reset_index(drop=True)\n",
    "data_dist = data_complete[data_complete['Class'] == 'dist'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60d7c5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-10-31 06:52:58,856 - kennard_stone.utils._pairwise:109[INFO] - Calculating pairwise distances using scikit-learn.\n",
      "\n",
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-10-31 06:52:58,864 - kennard_stone.utils._pairwise:109[INFO] - Calculating pairwise distances using scikit-learn.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-10-31 06:52:58,904 - kennard_stone.utils._pairwise:109[INFO] - Calculating pairwise distances using scikit-learn.\n",
      "\n",
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-10-31 06:52:58,909 - kennard_stone.utils._pairwise:109[INFO] - Calculating pairwise distances using scikit-learn.\n",
      "\n",
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into calibration and prediction sets by kennard-stone algorithm\n",
    "Xeut_cal, Xeut_pred = ks.train_test_split(data_eut.loc[:, '1':'15'], test_size=0.30) # class eutrophic\n",
    "Xeut_cal = Xeut_cal.reset_index(drop=True)\n",
    "Xeut_pred = Xeut_pred.reset_index(drop=True)\n",
    "\n",
    "Xdist_cal, Xdist_pred = ks.train_test_split(data_dist.loc[:, '1':'15'], test_size=0.30) # class dystrophic\n",
    "Xdist_cal = Xdist_cal.reset_index(drop=True)\n",
    "Xdist_pred = Xdist_pred.reset_index(drop=True)\n",
    "\n",
    "Xcal = pd.concat([Xeut_cal, Xdist_cal], axis=0).reset_index(drop=True) # concatenating both classes\n",
    "Xpred = pd.concat([Xeut_pred, Xdist_pred], axis=0).reset_index(drop=True)\n",
    "ycal = pd.Series(['eut']*Xeut_cal.shape[0] + ['dist']*Xdist_cal.shape[0]) # creating the target variable for calibration set\n",
    "ypred = pd.Series(['eut']*Xeut_pred.shape[0] + ['dist']*Xdist_pred.shape[0]) # creating the target variable for prediction set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7ecc374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessings\n",
    "import preprocessings as prepr # preprocessing methods for XRF data\n",
    "\n",
    "Xcal_prep, mean_cal, mean_cal_poisson  = prepr.poisson(Xcal, mc=True)\n",
    "Xpred_prep = ((Xpred/np.sqrt(mean_cal)) - mean_cal_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cc5dca04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LVs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Accuracy Cal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Sensitivity Cal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Specificity Cal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CM Cal",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Accuracy CV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Sensitivity CV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Specificity CV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CM CV",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Accuracy Pred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Sensitivity Pred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Specificity Pred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CM Pred",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "X Cum Exp Var",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Y Cum Exp Var",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "X Ind Exp Var",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Y Ind Exp Var",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ed3ba039-f95f-43c5-9db7-6010f4664ab2",
       "rows": [
        [
         "0",
         "1",
         "0.8040540540540541",
         "0.8450704225352113",
         "0.7662337662337663",
         "[[59 18]\n [11 60]]",
         "0.722972972972973",
         "0.7464788732394366",
         "0.7012987012987013",
         "[[54 23]\n [18 53]]",
         "0.75",
         "0.8709677419354839",
         "0.6363636363636364",
         "[[21 12]\n [ 4 27]]",
         "24.084452366773903",
         "18.486320379146374",
         "24.084452366773903",
         "18.486320379146374"
        ],
        [
         "1",
         "2",
         "0.8513513513513513",
         "0.9154929577464789",
         "0.7922077922077922",
         "[[61 16]\n [ 6 65]]",
         "0.8108108108108109",
         "0.8732394366197183",
         "0.7532467532467533",
         "[[58 19]\n [ 9 62]]",
         "0.84375",
         "0.967741935483871",
         "0.7272727272727273",
         "[[24  9]\n [ 1 30]]",
         "46.02580658097746",
         "20.883518301560077",
         "21.941354214203557",
         "2.397197922413703"
        ],
        [
         "2",
         "3",
         "0.831081081081081",
         "0.9014084507042254",
         "0.7662337662337663",
         "[[59 18]\n [ 7 64]]",
         "0.7972972972972973",
         "0.8450704225352113",
         "0.7532467532467533",
         "[[58 19]\n [11 60]]",
         "0.828125",
         "0.967741935483871",
         "0.696969696969697",
         "[[23 10]\n [ 1 30]]",
         "70.29145947510425",
         "21.96017415111487",
         "24.265652894126788",
         "1.0766558495547933"
        ],
        [
         "3",
         "4",
         "0.8716216216216216",
         "0.8873239436619719",
         "0.8571428571428571",
         "[[66 11]\n [ 8 63]]",
         "0.7702702702702703",
         "0.8450704225352113",
         "0.7012987012987013",
         "[[54 23]\n [11 60]]",
         "0.875",
         "0.967741935483871",
         "0.7878787878787878",
         "[[26  7]\n [ 1 30]]",
         "78.65594278703627",
         "24.395837065739926",
         "8.36448331193202",
         "2.4356629146250555"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LVs</th>\n",
       "      <th>Accuracy Cal</th>\n",
       "      <th>Sensitivity Cal</th>\n",
       "      <th>Specificity Cal</th>\n",
       "      <th>CM Cal</th>\n",
       "      <th>Accuracy CV</th>\n",
       "      <th>Sensitivity CV</th>\n",
       "      <th>Specificity CV</th>\n",
       "      <th>CM CV</th>\n",
       "      <th>Accuracy Pred</th>\n",
       "      <th>Sensitivity Pred</th>\n",
       "      <th>Specificity Pred</th>\n",
       "      <th>CM Pred</th>\n",
       "      <th>X Cum Exp Var</th>\n",
       "      <th>Y Cum Exp Var</th>\n",
       "      <th>X Ind Exp Var</th>\n",
       "      <th>Y Ind Exp Var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.804054</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>[[59, 18], [11, 60]]</td>\n",
       "      <td>0.722973</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>[[54, 23], [18, 53]]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>[[21, 12], [4, 27]]</td>\n",
       "      <td>24.084452</td>\n",
       "      <td>18.486320</td>\n",
       "      <td>24.084452</td>\n",
       "      <td>18.486320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>[[61, 16], [6, 65]]</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>[[58, 19], [9, 62]]</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>[[24, 9], [1, 30]]</td>\n",
       "      <td>46.025807</td>\n",
       "      <td>20.883518</td>\n",
       "      <td>21.941354</td>\n",
       "      <td>2.397198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>[[59, 18], [7, 64]]</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>[[58, 19], [11, 60]]</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>[[23, 10], [1, 30]]</td>\n",
       "      <td>70.291459</td>\n",
       "      <td>21.960174</td>\n",
       "      <td>24.265653</td>\n",
       "      <td>1.076656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.871622</td>\n",
       "      <td>0.887324</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>[[66, 11], [8, 63]]</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>[[54, 23], [11, 60]]</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>[[26, 7], [1, 30]]</td>\n",
       "      <td>78.655943</td>\n",
       "      <td>24.395837</td>\n",
       "      <td>8.364483</td>\n",
       "      <td>2.435663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LVs  Accuracy Cal  Sensitivity Cal  Specificity Cal                CM Cal  \\\n",
       "0    1      0.804054         0.845070         0.766234  [[59, 18], [11, 60]]   \n",
       "1    2      0.851351         0.915493         0.792208   [[61, 16], [6, 65]]   \n",
       "2    3      0.831081         0.901408         0.766234   [[59, 18], [7, 64]]   \n",
       "3    4      0.871622         0.887324         0.857143   [[66, 11], [8, 63]]   \n",
       "\n",
       "   Accuracy CV  Sensitivity CV  Specificity CV                 CM CV  \\\n",
       "0     0.722973        0.746479        0.701299  [[54, 23], [18, 53]]   \n",
       "1     0.810811        0.873239        0.753247   [[58, 19], [9, 62]]   \n",
       "2     0.797297        0.845070        0.753247  [[58, 19], [11, 60]]   \n",
       "3     0.770270        0.845070        0.701299  [[54, 23], [11, 60]]   \n",
       "\n",
       "   Accuracy Pred  Sensitivity Pred  Specificity Pred              CM Pred  \\\n",
       "0       0.750000          0.870968          0.636364  [[21, 12], [4, 27]]   \n",
       "1       0.843750          0.967742          0.727273   [[24, 9], [1, 30]]   \n",
       "2       0.828125          0.967742          0.696970  [[23, 10], [1, 30]]   \n",
       "3       0.875000          0.967742          0.787879   [[26, 7], [1, 30]]   \n",
       "\n",
       "   X Cum Exp Var  Y Cum Exp Var  X Ind Exp Var  Y Ind Exp Var  \n",
       "0      24.084452      18.486320      24.084452      18.486320  \n",
       "1      46.025807      20.883518      21.941354       2.397198  \n",
       "2      70.291459      21.960174      24.265653       1.076656  \n",
       "3      78.655943      24.395837       8.364483       2.435663  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing PLS-DA with optimized latent variables\n",
    "plsda_results = pls_optimized(Xcal_prep, \n",
    "                              ycal,\n",
    "                              LVmax=4,\n",
    "                              Xpred=Xpred_prep,\n",
    "                              ypred=ypred,\n",
    "                              aim='classification',\n",
    "                              cv=10)\n",
    "plsda_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "081134b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xcal_prep.to_csv('Xcal_prep_calss.csv', index=False, sep=';')\n",
    "# Xpred_prep.to_csv('Xpred_prep_class.csv', index=False, sep=';')\n",
    "# ycal.to_csv('ycal_class.csv', index=False, sep=';')\n",
    "# ypred.to_csv('ypred_class.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e52025",
   "metadata": {},
   "source": [
    "# **Regression case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "860a7ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-10-31 06:52:59,795 - kennard_stone.utils._pairwise:109[INFO] - Calculating pairwise distances using scikit-learn.\n",
      "\n",
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-10-31 06:52:59,800 - kennard_stone.utils._pairwise:109[INFO] - Calculating pairwise distances using scikit-learn.\n",
      "\n",
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into calibration and prediction sets by kennard-stone algorithm\n",
    "datacal, datapred = ks.train_test_split(data, test_size=0.25)\n",
    "Xcal = datacal.iloc[:, 1:].reset_index(drop=True)\n",
    "ycal = datacal.iloc[:, 0].reset_index(drop=True)\n",
    "Xpred = datapred.iloc[:, 1:].reset_index(drop=True)\n",
    "ypred = datapred.iloc[:, 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99c81cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessings\n",
    "import preprocessings as prepr # preprocessing methods for XRF data\n",
    "\n",
    "Xcal_prep, mean_cal, mean_cal_poisson  = prepr.poisson(Xcal, mc=True)\n",
    "Xpred_prep = ((Xpred/np.sqrt(mean_cal)) - mean_cal_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d9eb598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LVs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "R2 Cal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSEC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2 CV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSECV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RPD CV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RPIQ CV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Bias_CV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tbias_CV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2 Pred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSEP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RPD Pred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RPIQ Pred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Bias_Pred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tbias_Pred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "X Cum Exp Var",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Y Cum Exp Var",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "X Ind Exp Var",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Y Ind Exp Var",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "243c6538-f835-4d55-bc4b-d7d6078cc656",
       "rows": [
        [
         "0",
         "1",
         "0.6568825199587158",
         "1.051657610109096",
         "0.6227704256844663",
         "1.102696037114472",
         "1.63330447481488",
         "2.217292814797867",
         "-0.0020551113580734755",
         "0.023426577409654665",
         "0.355357370660464",
         "1.1504868510981576",
         "1.2574095435843593",
         "1.7210105427194227",
         "-0.43680826826479774",
         "2.9594591510241965",
         "22.69296789779639",
         "11.941666675756315",
         "22.69296789779639",
         "11.941666675756315"
        ],
        [
         "1",
         "2",
         "0.7363332261654805",
         "0.9218932808958307",
         "0.6514802934616697",
         "1.059904209207286",
         "1.6992463622035416",
         "2.306812237144188",
         "-0.005960336714421135",
         "0.07068700620721287",
         "0.622069583632002",
         "0.8809029649630492",
         "1.6422162302516738",
         "2.247693649303421",
         "-0.3342905664377916",
         "2.9577627097811585",
         "43.587588910164605",
         "13.38602517495073",
         "20.894621012368216",
         "1.444358499194415"
        ],
        [
         "2",
         "3",
         "0.7452865416883991",
         "0.9061057643323802",
         "0.6347459184003224",
         "1.085051835371941",
         "1.6598639005687048",
         "2.253348568515059",
         "-0.01292523160899632",
         "0.14974323336401993",
         "0.69022400072999",
         "0.797528170138884",
         "1.813895985752102",
         "2.482670925160169",
         "-0.25506991361711373",
         "2.434145068683927",
         "71.13351625656192",
         "13.548790214922096",
         "27.545927346397313",
         "0.16276503997136693"
        ],
        [
         "3",
         "4",
         "0.7695318981165918",
         "0.8619029348998829",
         "0.6258231483733178",
         "1.0982252010313744",
         "1.639953599761047",
         "2.226319335691652",
         "-0.035702121720774714",
         "0.40884696072395016",
         "0.7218579270916826",
         "0.7557105623480852",
         "1.914268793391315",
         "2.6200507160412014",
         "-0.30232787571264036",
         "3.147724219518338",
         "80.6437517349097",
         "13.989553907216091",
         "9.51023547834778",
         "0.44076369229399504"
        ],
        [
         "4",
         "5",
         "0.7812507669660347",
         "0.8397039894587413",
         "0.6299967741356634",
         "1.0920831398018442",
         "1.6491769775939367",
         "2.2388405341040607",
         "-0.0370536981704598",
         "0.42673132595709845",
         "0.7020116684549458",
         "0.7822071439055917",
         "1.849424615474673",
         "2.531298793966238",
         "-0.3021537225995317",
         "3.01993724600765",
         "90.92457934974018",
         "14.202594780378224",
         "10.280827614830486",
         "0.21304087316213227"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LVs</th>\n",
       "      <th>R2 Cal</th>\n",
       "      <th>RMSEC</th>\n",
       "      <th>R2 CV</th>\n",
       "      <th>RMSECV</th>\n",
       "      <th>RPD CV</th>\n",
       "      <th>RPIQ CV</th>\n",
       "      <th>Bias_CV</th>\n",
       "      <th>tbias_CV</th>\n",
       "      <th>R2 Pred</th>\n",
       "      <th>RMSEP</th>\n",
       "      <th>RPD Pred</th>\n",
       "      <th>RPIQ Pred</th>\n",
       "      <th>Bias_Pred</th>\n",
       "      <th>tbias_Pred</th>\n",
       "      <th>X Cum Exp Var</th>\n",
       "      <th>Y Cum Exp Var</th>\n",
       "      <th>X Ind Exp Var</th>\n",
       "      <th>Y Ind Exp Var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.656883</td>\n",
       "      <td>1.051658</td>\n",
       "      <td>0.622770</td>\n",
       "      <td>1.102696</td>\n",
       "      <td>1.633304</td>\n",
       "      <td>2.217293</td>\n",
       "      <td>-0.002055</td>\n",
       "      <td>0.023427</td>\n",
       "      <td>0.355357</td>\n",
       "      <td>1.150487</td>\n",
       "      <td>1.257410</td>\n",
       "      <td>1.721011</td>\n",
       "      <td>-0.436808</td>\n",
       "      <td>2.959459</td>\n",
       "      <td>22.692968</td>\n",
       "      <td>11.941667</td>\n",
       "      <td>22.692968</td>\n",
       "      <td>11.941667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.736333</td>\n",
       "      <td>0.921893</td>\n",
       "      <td>0.651480</td>\n",
       "      <td>1.059904</td>\n",
       "      <td>1.699246</td>\n",
       "      <td>2.306812</td>\n",
       "      <td>-0.005960</td>\n",
       "      <td>0.070687</td>\n",
       "      <td>0.622070</td>\n",
       "      <td>0.880903</td>\n",
       "      <td>1.642216</td>\n",
       "      <td>2.247694</td>\n",
       "      <td>-0.334291</td>\n",
       "      <td>2.957763</td>\n",
       "      <td>43.587589</td>\n",
       "      <td>13.386025</td>\n",
       "      <td>20.894621</td>\n",
       "      <td>1.444358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.745287</td>\n",
       "      <td>0.906106</td>\n",
       "      <td>0.634746</td>\n",
       "      <td>1.085052</td>\n",
       "      <td>1.659864</td>\n",
       "      <td>2.253349</td>\n",
       "      <td>-0.012925</td>\n",
       "      <td>0.149743</td>\n",
       "      <td>0.690224</td>\n",
       "      <td>0.797528</td>\n",
       "      <td>1.813896</td>\n",
       "      <td>2.482671</td>\n",
       "      <td>-0.255070</td>\n",
       "      <td>2.434145</td>\n",
       "      <td>71.133516</td>\n",
       "      <td>13.548790</td>\n",
       "      <td>27.545927</td>\n",
       "      <td>0.162765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.769532</td>\n",
       "      <td>0.861903</td>\n",
       "      <td>0.625823</td>\n",
       "      <td>1.098225</td>\n",
       "      <td>1.639954</td>\n",
       "      <td>2.226319</td>\n",
       "      <td>-0.035702</td>\n",
       "      <td>0.408847</td>\n",
       "      <td>0.721858</td>\n",
       "      <td>0.755711</td>\n",
       "      <td>1.914269</td>\n",
       "      <td>2.620051</td>\n",
       "      <td>-0.302328</td>\n",
       "      <td>3.147724</td>\n",
       "      <td>80.643752</td>\n",
       "      <td>13.989554</td>\n",
       "      <td>9.510235</td>\n",
       "      <td>0.440764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.781251</td>\n",
       "      <td>0.839704</td>\n",
       "      <td>0.629997</td>\n",
       "      <td>1.092083</td>\n",
       "      <td>1.649177</td>\n",
       "      <td>2.238841</td>\n",
       "      <td>-0.037054</td>\n",
       "      <td>0.426731</td>\n",
       "      <td>0.702012</td>\n",
       "      <td>0.782207</td>\n",
       "      <td>1.849425</td>\n",
       "      <td>2.531299</td>\n",
       "      <td>-0.302154</td>\n",
       "      <td>3.019937</td>\n",
       "      <td>90.924579</td>\n",
       "      <td>14.202595</td>\n",
       "      <td>10.280828</td>\n",
       "      <td>0.213041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LVs    R2 Cal     RMSEC     R2 CV    RMSECV    RPD CV   RPIQ CV   Bias_CV  \\\n",
       "0    1  0.656883  1.051658  0.622770  1.102696  1.633304  2.217293 -0.002055   \n",
       "1    2  0.736333  0.921893  0.651480  1.059904  1.699246  2.306812 -0.005960   \n",
       "2    3  0.745287  0.906106  0.634746  1.085052  1.659864  2.253349 -0.012925   \n",
       "3    4  0.769532  0.861903  0.625823  1.098225  1.639954  2.226319 -0.035702   \n",
       "4    5  0.781251  0.839704  0.629997  1.092083  1.649177  2.238841 -0.037054   \n",
       "\n",
       "   tbias_CV   R2 Pred     RMSEP  RPD Pred  RPIQ Pred  Bias_Pred  tbias_Pred  \\\n",
       "0  0.023427  0.355357  1.150487  1.257410   1.721011  -0.436808    2.959459   \n",
       "1  0.070687  0.622070  0.880903  1.642216   2.247694  -0.334291    2.957763   \n",
       "2  0.149743  0.690224  0.797528  1.813896   2.482671  -0.255070    2.434145   \n",
       "3  0.408847  0.721858  0.755711  1.914269   2.620051  -0.302328    3.147724   \n",
       "4  0.426731  0.702012  0.782207  1.849425   2.531299  -0.302154    3.019937   \n",
       "\n",
       "   X Cum Exp Var  Y Cum Exp Var  X Ind Exp Var  Y Ind Exp Var  \n",
       "0      22.692968      11.941667      22.692968      11.941667  \n",
       "1      43.587589      13.386025      20.894621       1.444358  \n",
       "2      71.133516      13.548790      27.545927       0.162765  \n",
       "3      80.643752      13.989554       9.510235       0.440764  \n",
       "4      90.924579      14.202595      10.280828       0.213041  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plsr_results = pls_optimized(Xcal_prep, ycal, \n",
    "                             LVmax=5, \n",
    "                             Xpred=Xpred_prep,\n",
    "                             ypred=ypred,\n",
    "                             aim='regression',\n",
    "                             cv=10)\n",
    "plsr_results[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
